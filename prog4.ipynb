{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping Dataset To 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dog images:  759\n",
      "length of annotations:  759\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import glob\n",
    "from PIL import Image \n",
    "import os \n",
    "classes = [\n",
    "    'n02111889-Samoyed',\n",
    "    'n02098286-West_Highland_white_terrier',\n",
    "    'n02085782-Japanese_spaniel',\n",
    "    'n02088466-bloodhound'\n",
    "]\n",
    "\n",
    "dog_images = list(chain.from_iterable([glob.glob(f'./Images/{cls}/*') for cls in classes]))\n",
    "annotations = list(chain.from_iterable([glob.glob(f'./Annotation/{cls}/*') for cls in classes]))\n",
    "\n",
    "dog_images = list(map(os.path.abspath, dog_images))\n",
    "annotations = list(map(os.path.abspath, annotations))\n",
    "\n",
    "print('length of dog images: ', len(dog_images))\n",
    "print('length of annotations: ', len(annotations))\n",
    "\n",
    "\n",
    "# Source: https://www.kaggle.com/code/espriella/stanford-dogs-transfer-crop-stack/notebook\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "def get_image(annot):\n",
    "    img_filename = annot.replace('Annotation', 'Images')\n",
    "    return img_filename + '.jpg'\n",
    "\n",
    "def get_bounding_boxes(annot):\n",
    "    xml = annot\n",
    "    tree = ET.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "    bbox = []\n",
    "    for o in objects:\n",
    "        bndbox = o.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        bbox.append((xmin,ymin,xmax,ymax))\n",
    "    return bbox\n",
    "\n",
    "if not os.path.exists('./Cropped/'):\n",
    "    for i in range(len(dog_images)):\n",
    "        bbox = get_bounding_boxes(annotations[i])\n",
    "        dog = get_image(annotations[i])\n",
    "        im = Image.open(dog)\n",
    "        for j in range(len(bbox)):\n",
    "            im2 = im.crop(bbox[j])\n",
    "            im2 = im2.resize((224,224), Image.ANTIALIAS)\n",
    "            new_path = dog.replace('Images','Cropped')\n",
    "            new_path = new_path.replace('.jpg','-' + str(j) + '.jpg')\n",
    "            im2=im2.convert('RGB')\n",
    "            head, tail = os.path.split(new_path)\n",
    "            Path(head).mkdir(parents=True, exist_ok=True)\n",
    "            im2.save(new_path)\n",
    "\n",
    "cropped_images = list(chain.from_iterable([glob.glob(f'./Cropped/{cls}/*') for cls in classes]))\n",
    "cropped_images = list(map(os.path.abspath, cropped_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Source: https://kozodoi.me/blog/20210527/extracting-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- preds shape: (320, 2)\n",
      "- feats shape: (320, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import PurePath\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ImageData(Dataset):\n",
    "    def __init__(self, filenames, transform):\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "        self.classes = [\n",
    "            'n02111889-Samoyed',\n",
    "            'n02098286-West_Highland_white_terrier',\n",
    "            'n02085782-Japanese_spaniel',\n",
    "            'n02088466-bloodhound'\n",
    "        ]\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        image = cv2.imread(filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image = image)['image']\n",
    "        label = PurePath(filename).parent.name\n",
    "        label_enc = self.classes.index(label)\n",
    "        return image, label_enc\n",
    "\n",
    "transforms = A.Compose([A.Normalize(),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "data_set = ImageData(cropped_images, transforms)\n",
    "\n",
    "data_loader = DataLoader(data_set, \n",
    "                         batch_size  = 32, \n",
    "                         shuffle     = False, \n",
    "                         num_workers = 0)\n",
    "\n",
    "model    = timm.create_model(model_name = 'resnet18', pretrained = True)\n",
    "model.fc = nn.Linear(512, 2)\n",
    "model.to(device)\n",
    "\n",
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "##### REGISTER HOOK\n",
    "model.global_pool.register_forward_hook(get_features('feats'))\n",
    "\n",
    "##### FEATURE EXTRACTION LOOP\n",
    "\n",
    "# placeholders\n",
    "PREDS = []\n",
    "LABELS = []\n",
    "FEATS = []\n",
    "\n",
    "# placeholder for batch features\n",
    "features = {}\n",
    "\n",
    "# loop through batches\n",
    "for idx, inputs in enumerate(data_loader):\n",
    "    labels = inputs[1]\n",
    "    inputs = inputs[0]\n",
    "    # move to device\n",
    "    inputs = inputs.to(device)\n",
    "       \n",
    "    # forward pass [with feature extraction]\n",
    "    preds = model(inputs)\n",
    "    \n",
    "    # add feats and preds to lists\n",
    "    PREDS.append(preds.detach().cpu().numpy())\n",
    "    FEATS.append(features['feats'].cpu().numpy())\n",
    "    LABELS.append(labels.cpu().numpy())\n",
    "\n",
    "    # early stop\n",
    "    if idx == 9:\n",
    "        break\n",
    "\n",
    "##### INSPECT FEATURES\n",
    "\n",
    "PREDS = np.concatenate(PREDS)\n",
    "LABELS = np.concatenate(LABELS)\n",
    "FEATS = np.concatenate(FEATS)\n",
    "\n",
    "print('- preds shape:', PREDS.shape)\n",
    "print('- feats shape:', FEATS.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "feats_2d = PCA(n_components=2).fit_transform(FEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clustering Alogrithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# DBSCAN #\n",
      "Number of clusters: 4\n",
      "eps: 0.3\n",
      "min_samples: 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "n_clusters = 4\n",
    "\n",
    "eps = 0.3\n",
    "min_samples = 5\n",
    "\n",
    "methods = {\n",
    "    'K-Means Random' : cluster.KMeans(n_clusters, init='random', n_init='auto').fit_predict(feats_2d),\n",
    "    'K-Means++' : cluster.KMeans(n_clusters, init='k-means++', n_init='auto').fit_predict(feats_2d),\n",
    "    'Bisecting K-Means' : cluster.BisectingKMeans(n_clusters, init='random').fit_predict(feats_2d),\n",
    "    'Spectral Clustering' : cluster.SpectralClustering(n_clusters).fit_predict(feats_2d),\n",
    "    'DBSCAN' : cluster.DBSCAN(eps=eps, min_samples=min_samples).fit_predict(feats_2d),\n",
    "    'Agglomerative (Single Link)' : cluster.AgglomerativeClustering(n_clusters, linkage='single').fit_predict(feats_2d),\n",
    "    'Agglomerative (Complete Link)' : cluster.AgglomerativeClustering(n_clusters, linkage='complete').fit_predict(feats_2d),\n",
    "    'Agglomerative (Group Average)' : cluster.AgglomerativeClustering(n_clusters, linkage='average').fit_predict(feats_2d),\n",
    "    'Agglomerative (Ward)' : cluster.AgglomerativeClustering(n_clusters, linkage='ward').fit_predict(feats_2d),\n",
    "}\n",
    "\n",
    "n_clusters_dbscan =  len(set(methods['DBSCAN']))\n",
    "print('# DBSCAN #')\n",
    "print(\"Number of clusters:\", n_clusters_dbscan)\n",
    "print(\"eps:\", eps)\n",
    "print(\"min_samples:\", min_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustering Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### K-Means Random ###\n",
      "\tFowlkes-Mallows Index: 0.42992487758249914\n",
      "\tSihlouette Score: 0.37478018\n",
      "\n",
      "### K-Means++ ###\n",
      "\tFowlkes-Mallows Index: 0.4373898918268066\n",
      "\tSihlouette Score: 0.3784739\n",
      "\n",
      "### Bisecting K-Means ###\n",
      "\tFowlkes-Mallows Index: 0.4383142604635883\n",
      "\tSihlouette Score: 0.36086938\n",
      "\n",
      "### Spectral Clustering ###\n",
      "\tFowlkes-Mallows Index: 0.5254860411137812\n",
      "\tSihlouette Score: 0.3380731\n",
      "\n",
      "### DBSCAN ###\n",
      "\tFowlkes-Mallows Index: 0.569283420893119\n",
      "\tSihlouette Score: 0.14869535\n",
      "\n",
      "### Agglomerative (Single Link) ###\n",
      "\tFowlkes-Mallows Index: 0.7814160508895514\n",
      "\tSihlouette Score: 0.20766315\n",
      "\n",
      "### Agglomerative (Complete Link) ###\n",
      "\tFowlkes-Mallows Index: 0.4405827511778126\n",
      "\tSihlouette Score: 0.27606922\n",
      "\n",
      "### Agglomerative (Group Average) ###\n",
      "\tFowlkes-Mallows Index: 0.6444704032836164\n",
      "\tSihlouette Score: 0.25265154\n",
      "\n",
      "### Agglomerative (Ward) ###\n",
      "\tFowlkes-Mallows Index: 0.4723955833984253\n",
      "\tSihlouette Score: 0.30179957\n",
      "\n",
      "Sorted by Fowlkes-Mallows Index:\n",
      "\tAgglomerative (Single Link)\n",
      "\tAgglomerative (Group Average)\n",
      "\tDBSCAN\n",
      "\tSpectral Clustering\n",
      "\tAgglomerative (Ward)\n",
      "\tAgglomerative (Complete Link)\n",
      "\tBisecting K-Means\n",
      "\tK-Means++\n",
      "\tK-Means Random\n",
      "Sorted by Sihlouette Score:\n",
      "\tK-Means++\n",
      "\tK-Means Random\n",
      "\tBisecting K-Means\n",
      "\tSpectral Clustering\n",
      "\tAgglomerative (Ward)\n",
      "\tAgglomerative (Complete Link)\n",
      "\tAgglomerative (Group Average)\n",
      "\tAgglomerative (Single Link)\n",
      "\tDBSCAN\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class Clustering:\n",
    "    def __init__(self, name, fowlkesMallows, sihlouette):\n",
    "        self.name = name\n",
    "        self.fowlkesMallows = fowlkesMallows\n",
    "        self.sihlouette = sihlouette\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "stats = []\n",
    "\n",
    "for name, clustering in methods.items():\n",
    "    fm = metrics.fowlkes_mallows_score(LABELS, clustering)\n",
    "    s = metrics.silhouette_score(feats_2d, clustering)\n",
    "    stats.append(Clustering(name, fm, s))\n",
    "    print(f\"### {name} ###\")\n",
    "    print('\\tFowlkes-Mallows Index:', fm)\n",
    "    print('\\tSihlouette Score:', s)\n",
    "    print()\n",
    "\n",
    "sorted_fowlkesMallows = reversed(sorted(stats, key=lambda c : c.fowlkesMallows))\n",
    "sorted_sihlouette = reversed(sorted(stats, key=lambda c : c.sihlouette))\n",
    "\n",
    "print(\"Sorted by Fowlkes-Mallows Index:\")\n",
    "for c in sorted_fowlkesMallows:\n",
    "    print('\\t'+str(c))\n",
    "print(\"Sorted by Sihlouette Score:\")\n",
    "for c in sorted_sihlouette:\n",
    "    print('\\t'+str(c))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
